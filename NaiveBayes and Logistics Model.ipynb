{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noonum Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "#import nltk\n",
    "#from nltk.corpus import wordnet as wn\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.corpus.reader.wordnet import WordNetError\n",
    "#stopset = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data\n",
    "\n",
    "Two datasets were used in this project. \n",
    "\n",
    "<b> 1.IMDB Dataset (65.9 MB)</b> \n",
    "<br>IMDB Dataset consists of 50,000 IMDB movie reviews, specially selected for sentiment analysis. The sentiment of reviews is binary, meaning the IMDB rating < 5 results in a sentiment score of 0, and rating >=7 have a sentiment score of 1. 25,000 of them are labeled with sentiment score, therefore used as training corpus. </br>\n",
    "\n",
    "<b> 2.Twitter Data (157 MB)</b>\n",
    "<br>Twitter Data is based on data from two sources:  </br>\n",
    "<br>1.University of Michigan Sentiment Analysis competition on Kaggle (https://inclass.kaggle.com/c/si650winter11)</br>\n",
    "<br>2.Twitter Sentiment Corpus by Niek Sanders (http://www.sananalytics.com/lab/twitter-sentiment/) </br>\n",
    "<br>This dataset contains 1,578,627 classified tweets, each row is marked as 1 for positive sentiment and 0 for negative sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8836: expected 4 fields, saw 5\\n'\n",
      "b'Skipping line 535882: expected 4 fields, saw 7\\n'\n"
     ]
    }
   ],
   "source": [
    "# IMDB Movie Review Dataset\n",
    "IMDB = pd.read_csv(\"labeledTrainData.tsv\", header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)\n",
    "# Twitter Dataset\n",
    "twitter = pd.read_csv('all.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_series_to_list(review_series):\n",
    "    review_list=[]\n",
    "    n_review = len(review_series)\n",
    "    for i in range(0,n_review):\n",
    "        review_list.append(review_series[i])\n",
    "    return review_list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tw_review_list = review_series_to_list(twitter['SentimentText'])\n",
    "tw_X_train, tw_X_test, tw_y_train, tw_y_test = train_test_split(\n",
    "    tw_review_list, twitter['Sentiment'], test_size=0.33, random_state=42)\n",
    "\n",
    "train_review_list = review_series_to_list(IMDB['review'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_review_list, IMDB['sentiment'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Accuracy\n",
    "### 2.f1 score\n",
    "### 3.ROC_AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection \n",
    "\n",
    "1. Logistics Regression\n",
    "2. Naive Bayes \n",
    "3. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Since IMDB is a smaller dataset, we will use this dataset to test which combination has the highest accuracy. We will just use default settings here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on IMDB data and testing on IMDB data...\n",
      "LR BOW\n",
      "Training Logistics model...\n",
      "Using Bag of Words...\n",
      "0.88496969697\n",
      "Accuracy 10cv : 0.88 (+/- 0.01)\n",
      "LR TFIDF\n",
      "Training Logistics model...\n",
      "Using TFIDF...\n",
      "0.889818181818\n",
      "Accuracy 10cv : 0.88 (+/- 0.01)\n",
      "NB BOW\n",
      "Training Naive Bayes model...\n",
      "Using Bag of Words...\n",
      "0.854545454545\n",
      "Accuracy 10cv : 0.85 (+/- 0.03)\n",
      "NB TFIDF\n",
      "Training Naive Bayes model...\n",
      "Using TFIDF...\n",
      "0.864848484848\n",
      "Accuracy 10cv : 0.86 (+/- 0.03)\n",
      "SVM BOW\n",
      "Training SVM model...\n",
      "Using Bag of Words...\n",
      "0.841333333333\n",
      "Accuracy 10cv : 0.83 (+/- 0.07)\n",
      "SVM TFIDF\n",
      "Training SVM model...\n",
      "Using TFIDF...\n",
      "0.895757575758\n",
      "Accuracy 10cv : 0.89 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "train = {'IMDB','twitter'}\n",
    "test = {'Twitter'}   tw_y_test\n",
    "'''\n",
    "training_model = ['LR','NB','SVM']\n",
    "vectorizer = ['BOW','TFIDF']\n",
    "\n",
    "def model_training(training_model,vectorizer):\n",
    "    if training_model == 'LR':\n",
    "        print (\"Training Logistics model...\")\n",
    "        if vectorizer == 'BOW':\n",
    "            print (\"Using Bag of Words...\")\n",
    "            model_LR_BOW = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', LR()),])\n",
    "            return model_LR_BOW\n",
    "           \n",
    "        elif vectorizer == 'TFIDF':\n",
    "            print (\"Using TFIDF...\")\n",
    "            model_LR_TFIDF = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LR()),])\n",
    "            return model_LR_TFIDF\n",
    "            \n",
    "    elif training_model == 'NB':\n",
    "        print (\"Training Naive Bayes model...\")\n",
    "        if vectorizer == 'BOW':\n",
    "            print (\"Using Bag of Words...\")\n",
    "            model_NB_BOW = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', MultinomialNB()),])\n",
    "            return model_NB_BOW\n",
    "                        \n",
    "        elif vectorizer == 'TFIDF':\n",
    "            print (\"Using TFIDF...\")\n",
    "            model_NB_TFIDF = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),])\n",
    "            return model_NB_TFIDF\n",
    "    \n",
    "    elif training_model == 'SVM':\n",
    "        print (\"Training SVM model...\")\n",
    "        if vectorizer == 'BOW':\n",
    "            print (\"Using Bag of Words...\")\n",
    "            model_SVM_BOW = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf', SGDClassifier()),])\n",
    "            return model_SVM_BOW\n",
    "                        \n",
    "        elif vectorizer == 'TFIDF':\n",
    "            print (\"Using TFIDF...\")\n",
    "            model_SVM_TFIDF = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier()),])\n",
    "            return model_SVM_TFIDF\n",
    "                    \n",
    "def model_fitting_in_different_dataset(train,test):\n",
    "    if train == 'IMDB' and test == 'Twitter':       \n",
    "        print ('Training model on IMDB data and testing on Twitter data...') \n",
    "        for i in training_model:\n",
    "            for j in vectorizer:\n",
    "                print (i,j)\n",
    "                fit_model1 = model_training(i,j).fit(X_train, y_train)\n",
    "                predicted1 = fit_model1.predict(tw_X_test)\n",
    "                accuracy1 = np.mean(predicted1 == tw_y_test)\n",
    "                print (accuracy1)\n",
    "            \n",
    "    elif train == 'Twitter' and test == 'Twitter':\n",
    "        print ('Training model on Twitter data and testing on Twitter data...')\n",
    "        for i in training_model:\n",
    "            for j in vectorizer:\n",
    "                print (i,j)\n",
    "                fit_model2 = model_training(i,j).fit(tw_X_train, tw_y_train)\n",
    "                predicted2 = fit_model2.predict(tw_X_test)\n",
    "                accuracy2 = np.mean(predicted2 == tw_y_test)\n",
    "                print (accuracy2)\n",
    "                \n",
    "       \n",
    "    elif train == 'IMDB' and test == 'IMDB':\n",
    "        print ('Training model on IMDB data and testing on IMDB data...')\n",
    "        for i in training_model:\n",
    "            for j in vectorizer:\n",
    "                print (i,j)\n",
    "                fit_model3 = model_training(i,j).fit(X_train, y_train)\n",
    "                #cv5 = cross_val_score(fit_model3, X_train, y_train, cv=5)\n",
    "                predicted3 = fit_model3.predict(X_test)\n",
    "                accuracy3 = np.mean(predicted3 == y_test)\n",
    "                scores10 = cross_val_score(fit_model3, X_train, y_train, cv=10)\n",
    "                print (accuracy3)\n",
    "                print(\"Accuracy 10cv : %0.2f (+/- %0.2f)\" % (scores10.mean(), scores10.std() * 2))\n",
    "                #print (\"5 fold cross validation for training data: \",cv5)\n",
    "                \n",
    "    \n",
    "    \n",
    "\n",
    "model_fitting_in_different_dataset('IMDB','IMDB')\n",
    "#print (cross_val_score(fit_model3, train, test, cv=5) )\n",
    "\n",
    "# Can also use this to test the model combination on Twitter dataset, but take longer time.\n",
    "# model_fitting_in_different_dataset('Twitter','Twitter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.87529833,  0.8872315 ,  0.88424821,  0.87708831,  0.88961814,\n",
       "        0.87335723,  0.88590203,  0.88351254,  0.87275986,  0.87037037])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LR()),])\n",
    "model =model.fit(X_train, y_train)\n",
    "cross_val_score(model, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: In IMDB dataset, we can find out the TFIDF works better than BOW. LR and SVM works better than Naive Bayes model in default parameter setting. Therefore, we can try to use grid search to find the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune LR + TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tuning parameters\n",
    "def logistics_model_withGS(train_X, train_y,val_X,val_y):# may take several hours to run\n",
    "    LR_withGS = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         #Dimensionality reduction using truncated SVD\n",
    "                         ('tsvd', TruncatedSVD()),\n",
    "                         ('clf', LR()),\n",
    "                         ])\n",
    "\n",
    "    parameters = {'vect__ngram_range': [(1, 1),(1,2)],\n",
    "                  #'vect__stop_words': (None, 'english'),\n",
    "                  'vect__lowercase': (True, False),\n",
    "                  #'tfidf__use_idf': (True, False),\n",
    "                  #'tsvd__n_components': (1100, ),\n",
    "                  #'clf__penalty': ('l1', 'l2'),\n",
    "                  #'clf__C': [0.1, 1]\n",
    "                  }\n",
    "    print ('Start grid search' )\n",
    "    gs_clf = GridSearchCV(LR_withGS, parameters,scores = 'accuracy')\n",
    "    fit_gs_clf = gs_clf.fit(train_X, train_y)\n",
    "    pred_gs_clf = fit_gs_clf.predict(val_X)\n",
    "    accuracy = \n",
    "    \n",
    "    print (gs_clf)\n",
    "    gs_clf.fit(data, target)\n",
    "    return gs_clf.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistics_model_default(train_X, train_y,val_X,val_y):\n",
    "    LR_default = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         #Dimensionality reduction using truncated SVD\n",
    "                         #('tsvd', TruncatedSVD()),\n",
    "                         ('clf', LR()),\n",
    "                         ])\n",
    "    LR_default = LR_default.fit(data,target)\n",
    "    pre_LR_default = \n",
    "    print (gs_clf)\n",
    "    gs_clf.fit(data, target)\n",
    "    return gs_clf.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start grid search\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))]),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'vect__ngram_range': [(1, 1), (1, 2)], 'vect__lowercase': (True, False)},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))]),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'vect__ngram_range': [(1, 1), (1, 2)], 'vect__lowercase': (True, False)},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n",
      "{'vect__lowercase': True, 'vect__ngram_range': (1, 1)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'vect__ngram_range': [(1, 1), (1, 2)], 'vect__lowercase': (True, False)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistics_model_withGS(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.864848484848\n"
     ]
    }
   ],
   "source": [
    "# nb model train IMDB test TFIDF\n",
    "nb_model = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "nb_fit = nb_model.fit(X_train, y_train)\n",
    "tw_nb_predicted = nb_model.predict(X_test)\n",
    "tw_nb_accuracy = np.mean(tw_nb_predicted == y_test) \n",
    "print (tw_nb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.886666666667\n"
     ]
    }
   ],
   "source": [
    "# remove stopwords and add ngram range \n",
    "nb_model = Pipeline([('vect', TfidfVectorizer(stop_words=stopset,ngram_range = (1,3))),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "nb_fit = nb_model.fit(X_train, y_train)\n",
    "tw_nb_predicted = nb_model.predict(X_test)\n",
    "tw_nb_accuracy = np.mean(tw_nb_predicted == y_test) \n",
    "print (tw_nb_accuracy)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
